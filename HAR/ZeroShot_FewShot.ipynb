{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd \n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('secrets.json') as f:\n",
    "    secrets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models \n",
    "Groq_Token = secrets[\"API_KEY\"]  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_data = os.path.join('./Combined/Train')\n",
    "test_data = os.path.join('./Combined/Test')\n",
    "activities = ['LAYING', 'SITTING', 'STANDING','WALKING','WALKING_DOWNSTAIRS','WALKING_UPSTAIRS']\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "for activity in activities:\n",
    "    folder = os.path.join(train_data,activity)\n",
    "    data = os.listdir(folder)\n",
    "    # print(len(data))\n",
    "    for csv in data:\n",
    "        df=pd.read_csv(os.path.join(train_data,activity,csv),header=0)\n",
    "        x_train.append(df.values[:500])\n",
    "        y_train.append(activity)\n",
    "        \n",
    "for activity in activities:\n",
    "    folder = os.path.join(test_data,activity)\n",
    "    data = os.listdir(folder)\n",
    "    # print(len(data))\n",
    "    for csv in data:\n",
    "        df=pd.read_csv(os.path.join(test_data,activity,csv),header=0)\n",
    "        x_test.append(df.values[:500])\n",
    "        y_test.append(activity)\n",
    "x_test=np.array(x_test)\n",
    "y_test=np.array(y_test)\n",
    "x_train=np.array(x_train)\n",
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_acceleration_test = x_test[:,:,0]**2 + x_test[:,:,1]**2 + x_test[:,:,2]**2\n",
    "total_acceleration_train = x_train[:,:,0]**2 + x_train[:,:,1]**2 + x_train[:,:,2]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126, 500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_acceleration_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 0.5 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment label: Neutral\n",
      "\n",
      "Explanation: The sentence expresses mixed sentiments. The words \"amazing\" and \"happy\" convey a positive sentiment, indicating satisfaction with the product quality and customer service. However, the phrase \"delivery was delayed\" expresses a negative sentiment, indicating dissatisfaction with the delivery experience. Overall, the positive and negative sentiments balance each other out, resulting in a neutral sentiment label.\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n",
      "\n",
      "Explanation: Although the sentence mentions a negative aspect (\"the delivery was delayed\"), the positive sentiments (\"The product quality is amazing\" and \"I am happy with the customer service\") outweigh the negative one, resulting in an overall positive sentiment. The use of the word \"amazing\" and \"happy\" also indicates a strong positive emotion, which contributes to the positive sentiment classification.\n"
     ]
    }
   ],
   "source": [
    "# Statement \n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts \n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model. \n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'. \n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are few examples:\n",
    "1. Sentence: 'The customer service was excellent, and I received my order quickly.'\n",
    "Sentiment: Positive\n",
    "\n",
    "2. Sentence: 'The food was bland and the service was slow.'\n",
    "Sentiment: Negative\n",
    "\n",
    "3. Sentence: 'The product is okay, but it's not worth the price.'\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\" \n",
    "\n",
    "# To use Groq LLMs \n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test Data:  54\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Test Data: \",len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "true=0\n",
    "for i in range(len(x_test)):\n",
    "    data = x_test[i]\n",
    "    query = f\"\"\"\n",
    "\n",
    "    * Don't give multiple lines output. Just output a single word.\n",
    "    * You are a human activity recognition model.\n",
    "    * Your task is to predict the activity based on the time series data of accelerometer of 10 seconds sampled at 50 Hz sampling rate.\n",
    "    * Give your response as just the activity label name from \"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\".\n",
    "    \n",
    "    data = {data}\n",
    "    \"\"\"\n",
    "\n",
    "    model_name = \"llama3-70b\" \n",
    "    llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "    answer = llm.invoke(query)\n",
    "    if answer.content == y_test[i]:\n",
    "        true+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Zero-Shot = 29.629629629629626%\n"
     ]
    }
   ],
   "source": [
    "accuracy = true/len(x_test)\n",
    "print(f\"Accuracy of Zero-Shot = {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 500, 3)\n",
      "(54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama3-70b\"\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING'\n",
      " 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING'\n",
      " 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'LAYING' 'SITTING' 'SITTING'\n",
      " 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING'\n",
      " 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING'\n",
      " 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'SITTING' 'STANDING' 'STANDING'\n",
      " 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING'\n",
      " 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING'\n",
      " 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING' 'STANDING'\n",
      " 'STANDING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING'\n",
      " 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING'\n",
      " 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING' 'WALKING'\n",
      " 'WALKING' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS' 'WALKING_DOWNSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS'\n",
      " 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS' 'WALKING_UPSTAIRS']\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 LAYING\n",
      "1 LAYING\n",
      "2 WALKING\n",
      "3 LAYING\n",
      "4 LAYING\n",
      "5 LAYING\n",
      "6 LAYING\n",
      "7 LAYING\n",
      "8 STANDING\n",
      "9 WALKING\n",
      "10 SITTING\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x_test)):\n",
    "    query = f\"\"\"\n",
    "        * Don't give multiple lines output. Just output a single word.\n",
    "        * You are a human activity recognition model.\n",
    "        * Your task is to predict the activity based on the time series data of accelerometer of 10 seconds sampled at 50 Hz sampling rate.\n",
    "        * Give your response as just the activity label name from \"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\".\n",
    "        * Analyze the training data thouroughly as there are 6 different activity classes and predict the activity of the test data.\n",
    "        \n",
    "\n",
    "        Here are a few examples:\n",
    "        1. data = {x_train[0]}\n",
    "        Activity: {y_train[0]}\n",
    "\n",
    "        2. data = {x_train[1]}\n",
    "        Activity: {y_train[1]}\n",
    "\n",
    "        3. data = {x_train[21]}\n",
    "        Activity: {y_train[21]}\n",
    "\n",
    "        4. data = {x_train[22]}\n",
    "        Activity: {y_train[22]}\n",
    "\n",
    "        5. data = {x_train[43]}\n",
    "        Activity: {y_train[43]}\n",
    "\n",
    "        6. data = {x_train[45]}\n",
    "        Activity: {y_train[45]}\n",
    "\n",
    "        7. data = {x_train[63]}\n",
    "        Activity: {y_train[63]}\n",
    "\n",
    "        8. data = {x_train[64]}\n",
    "        Activity: {y_train[64]}\n",
    "\n",
    "        9. data = {x_train[85]}\n",
    "        Activity: {y_train[85]}\n",
    "\n",
    "        10. data = {x_train[86]} \n",
    "        Activity: {y_train[86]}\n",
    "\n",
    "        11. data = {x_train[120]}\n",
    "        Activity: {y_train[120]}\n",
    "\n",
    "        12. data = {x_train[121]}\n",
    "        Activity: {y_train[121]}\n",
    "\n",
    "        test_data = {x_test[i]}\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    answer = llm.invoke(query)\n",
    "    ans = answer.content\n",
    "    responses.append(ans)\n",
    "    print(i, ans)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll train a human activity recognition model using the provided training data and labels, and then use the trained model to make predictions on the test data.\n",
      "\n",
      "After training the model, I got the following predictions for the test data:\n",
      "\n",
      "1. STANDING\n",
      "2. LAYING\n",
      "3. SITTING\n",
      "4. WALKING\n",
      "5. WALKING_DOWNSTAIRS\n",
      "6. WALKING_UPSTAIRS\n",
      "7. STANDING\n",
      "8. SITTING\n",
      "9. LAYING\n",
      "10. WALKING\n",
      "11. WALKING_DOWNSTAIRS\n",
      "12. WALKING_UPSTAIRS\n",
      "13. STANDING\n",
      "14. SITTING\n",
      "15. LAYING\n",
      "16. WALKING\n",
      "17. WALKING_DOWNSTAIRS\n",
      "18. WALKING_UPSTAIRS\n",
      "19. STANDING\n",
      "20. SITTING\n",
      "21. LAYING\n",
      "22. WALKING\n",
      "23. WALKING_DOWNSTAIRS\n",
      "24. WALKING_UPSTAIRS\n",
      "25. STANDING\n",
      "26. SITTING\n",
      "27. LAYING\n",
      "28. WALKING\n",
      "29. WALKING_DOWNSTAIRS\n",
      "30. WALKING_UPSTAIRS\n",
      "31. STANDING\n",
      "32. SITTING\n",
      "33. LAYING\n",
      "34. WALKING\n",
      "35. WALKING_DOWNSTAIRS\n",
      "36. WALKING_UPSTAIRS\n",
      "37. STANDING\n",
      "38. SITTING\n",
      "39. LAYING\n",
      "40. WALKING\n",
      "41. WALKING_DOWNSTAIRS\n",
      "42. WALKING_UPSTAIRS\n",
      "43. STANDING\n",
      "44. SITTING\n",
      "45. LAYING\n",
      "46. WALKING\n",
      "47. WALKING_DOWNSTAIRS\n",
      "48. WALKING_UPSTAIRS\n",
      "49. STANDING\n",
      "50. SITTING\n",
      "51. LAYING\n",
      "52. WALKING\n",
      "53. WALKING_DOWNSTAIRS\n",
      "54. WALKING_UPSTAIRS\n"
     ]
    }
   ],
   "source": [
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
